{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "textCleaning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-PnYfkY9fks",
        "colab_type": "code",
        "outputId": "cc245270-5d94-476e-bfd0-c2f842fcfd01",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 162
        }
      },
      "source": [
        "#upload attention.py and contractions.py\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dbc9edf4-d38d-4c46-be1f-66c7644aef47\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-dbc9edf4-d38d-4c46-be1f-66c7644aef47\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving attention.py to attention.py\n",
            "Saving contractions.py to contractions.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention.py': b'import tensorflow as tf\\r\\nimport os\\r\\nfrom tensorflow.python.keras.layers import Layer\\r\\nfrom tensorflow.python.keras import backend as K\\r\\n\\r\\n\\r\\nclass AttentionLayer(Layer):\\r\\n    \"\"\"\\r\\n    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\\r\\n    There are three sets of weights introduced W_a, U_a, and V_a\\r\\n     \"\"\"\\r\\n\\r\\n    def __init__(self, **kwargs):\\r\\n        super(AttentionLayer, self).__init__(**kwargs)\\r\\n\\r\\n    def build(self, input_shape):\\r\\n        assert isinstance(input_shape, list)\\r\\n        # Create a trainable weight variable for this layer.\\r\\n\\r\\n        self.W_a = self.add_weight(name=\\'W_a\\',\\r\\n                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\\r\\n                                   initializer=\\'uniform\\',\\r\\n                                   trainable=True)\\r\\n        self.U_a = self.add_weight(name=\\'U_a\\',\\r\\n                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\\r\\n                                   initializer=\\'uniform\\',\\r\\n                                   trainable=True)\\r\\n        self.V_a = self.add_weight(name=\\'V_a\\',\\r\\n                                   shape=tf.TensorShape((input_shape[0][2], 1)),\\r\\n                                   initializer=\\'uniform\\',\\r\\n                                   trainable=True)\\r\\n\\r\\n        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\\r\\n\\r\\n    def call(self, inputs, verbose=False):\\r\\n        \"\"\"\\r\\n        inputs: [encoder_output_sequence, decoder_output_sequence]\\r\\n        \"\"\"\\r\\n        assert type(inputs) == list\\r\\n        encoder_out_seq, decoder_out_seq = inputs\\r\\n        if verbose:\\r\\n            print(\\'encoder_out_seq>\\', encoder_out_seq.shape)\\r\\n            print(\\'decoder_out_seq>\\', decoder_out_seq.shape)\\r\\n\\r\\n        def energy_step(inputs, states):\\r\\n            \"\"\" Step function for computing energy for a single decoder state \"\"\"\\r\\n\\r\\n            assert_msg = \"States must be a list. However states {} is of type {}\".format(states, type(states))\\r\\n            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\\r\\n\\r\\n            \"\"\" Some parameters required for shaping tensors\"\"\"\\r\\n            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\\r\\n            de_hidden = inputs.shape[-1]\\r\\n\\r\\n            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\\r\\n            # <= batch_size*en_seq_len, latent_dim\\r\\n            reshaped_enc_outputs = K.reshape(encoder_out_seq, (-1, en_hidden))\\r\\n            # <= batch_size*en_seq_len, latent_dim\\r\\n            W_a_dot_s = K.reshape(K.dot(reshaped_enc_outputs, self.W_a), (-1, en_seq_len, en_hidden))\\r\\n            if verbose:\\r\\n                print(\\'wa.s>\\',W_a_dot_s.shape)\\r\\n\\r\\n            \"\"\" Computing hj.Ua \"\"\"\\r\\n            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\\r\\n            if verbose:\\r\\n                print(\\'Ua.h>\\',U_a_dot_h.shape)\\r\\n\\r\\n            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\\r\\n            # <= batch_size*en_seq_len, latent_dim\\r\\n            reshaped_Ws_plus_Uh = K.tanh(K.reshape(W_a_dot_s + U_a_dot_h, (-1, en_hidden)))\\r\\n            if verbose:\\r\\n                print(\\'Ws+Uh>\\', reshaped_Ws_plus_Uh.shape)\\r\\n\\r\\n            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\\r\\n            # <= batch_size, en_seq_len\\r\\n            e_i = K.reshape(K.dot(reshaped_Ws_plus_Uh, self.V_a), (-1, en_seq_len))\\r\\n            # <= batch_size, en_seq_len\\r\\n            e_i = K.softmax(e_i)\\r\\n\\r\\n            if verbose:\\r\\n                print(\\'ei>\\', e_i.shape)\\r\\n\\r\\n            return e_i, [e_i]\\r\\n\\r\\n        def context_step(inputs, states):\\r\\n            \"\"\" Step function for computing ci using ei \"\"\"\\r\\n            # <= batch_size, hidden_size\\r\\n            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\\r\\n            if verbose:\\r\\n                print(\\'ci>\\', c_i.shape)\\r\\n            return c_i, [c_i]\\r\\n\\r\\n        def create_inital_state(inputs, hidden_size):\\r\\n            # We are not using initial states, but need to pass something to K.rnn funciton\\r\\n            fake_state = K.zeros_like(inputs)  # <= (batch_size, enc_seq_len, latent_dim\\r\\n            fake_state = K.sum(fake_state, axis=[1, 2])  # <= (batch_size)\\r\\n            fake_state = K.expand_dims(fake_state)  # <= (batch_size, 1)\\r\\n            fake_state = K.tile(fake_state, [1, hidden_size])  # <= (batch_size, latent_dim\\r\\n            return fake_state\\r\\n\\r\\n        fake_state_c = create_inital_state(encoder_out_seq, encoder_out_seq.shape[-1])\\r\\n        fake_state_e = create_inital_state(encoder_out_seq, encoder_out_seq.shape[1])  # <= (batch_size, enc_seq_len, latent_dim\\r\\n\\r\\n        \"\"\" Computing energy outputs \"\"\"\\r\\n        # e_outputs => (batch_size, de_seq_len, en_seq_len)\\r\\n        last_out, e_outputs, _ = K.rnn(\\r\\n            energy_step, decoder_out_seq, [fake_state_e],\\r\\n        )\\r\\n\\r\\n        \"\"\" Computing context vectors \"\"\"\\r\\n        last_out, c_outputs, _ = K.rnn(\\r\\n            context_step, e_outputs, [fake_state_c],\\r\\n        )\\r\\n\\r\\n        return c_outputs, e_outputs\\r\\n\\r\\n    def compute_output_shape(self, input_shape):\\r\\n        \"\"\" Outputs produced by the layer \"\"\"\\r\\n        return [\\r\\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\\r\\n            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\\r\\n        ]',\n",
              " 'contractions.py': b'contraction_mapping = { \\r\\n\"ain\\'t\": \"am not / are not / is not / has not / have not\",\\r\\n\"aren\\'t\": \"are not / am not\",\\r\\n\"can\\'t\": \"cannot\",\\r\\n\"can\\'t\\'ve\": \"cannot have\",\\r\\n\"\\'cause\": \"because\",\\r\\n\"could\\'ve\": \"could have\",\\r\\n\"couldn\\'t\": \"could not\",\\r\\n\"couldn\\'t\\'ve\": \"could not have\",\\r\\n\"didn\\'t\": \"did not\",\\r\\n\"doesn\\'t\": \"does not\",\\r\\n\"don\\'t\": \"do not\",\\r\\n\"hadn\\'t\": \"had not\",\\r\\n\"hadn\\'t\\'ve\": \"had not have\",\\r\\n\"hasn\\'t\": \"has not\",\\r\\n\"haven\\'t\": \"have not\",\\r\\n\"he\\'d\": \"he had / he would\",\\r\\n\"he\\'d\\'ve\": \"he would have\",\\r\\n\"he\\'ll\": \"he shall / he will\",\\r\\n\"he\\'ll\\'ve\": \"he shall have / he will have\",\\r\\n\"he\\'s\": \"he has / he is\",\\r\\n\"how\\'d\": \"how did\",\\r\\n\"how\\'d\\'y\": \"how do you\",\\r\\n\"how\\'ll\": \"how will\",\\r\\n\"how\\'s\": \"how has / how is / how does\",\\r\\n\"I\\'d\": \"I had / I would\",\\r\\n\"I\\'d\\'ve\": \"I would have\",\\r\\n\"I\\'ll\": \"I shall / I will\",\\r\\n\"I\\'ll\\'ve\": \"I shall have / I will have\",\\r\\n\"I\\'m\": \"I am\",\\r\\n\"I\\'ve\": \"I have\",\\r\\n\"isn\\'t\": \"is not\",\\r\\n\"it\\'d\": \"it had / it would\",\\r\\n\"it\\'d\\'ve\": \"it would have\",\\r\\n\"it\\'ll\": \"it shall / it will\",\\r\\n\"it\\'ll\\'ve\": \"it shall have / it will have\",\\r\\n\"it\\'s\": \"it has / it is\",\\r\\n\"let\\'s\": \"let us\",\\r\\n\"ma\\'am\": \"madam\",\\r\\n\"mayn\\'t\": \"may not\",\\r\\n\"might\\'ve\": \"might have\",\\r\\n\"mightn\\'t\": \"might not\",\\r\\n\"mightn\\'t\\'ve\": \"might not have\",\\r\\n\"must\\'ve\": \"must have\",\\r\\n\"mustn\\'t\": \"must not\",\\r\\n\"mustn\\'t\\'ve\": \"must not have\",\\r\\n\"needn\\'t\": \"need not\",\\r\\n\"needn\\'t\\'ve\": \"need not have\",\\r\\n\"o\\'clock\": \"of the clock\",\\r\\n\"oughtn\\'t\": \"ought not\",\\r\\n\"oughtn\\'t\\'ve\": \"ought not have\",\\r\\n\"shan\\'t\": \"shall not\",\\r\\n\"sha\\'n\\'t\": \"shall not\",\\r\\n\"shan\\'t\\'ve\": \"shall not have\",\\r\\n\"she\\'d\": \"she had / she would\",\\r\\n\"she\\'d\\'ve\": \"she would have\",\\r\\n\"she\\'ll\": \"she shall / she will\",\\r\\n\"she\\'ll\\'ve\": \"she shall have / she will have\",\\r\\n\"she\\'s\": \"she has / she is\",\\r\\n\"should\\'ve\": \"should have\",\\r\\n\"shouldn\\'t\": \"should not\",\\r\\n\"shouldn\\'t\\'ve\": \"should not have\",\\r\\n\"so\\'ve\": \"so have\",\\r\\n\"so\\'s\": \"so as / so is\",\\r\\n\"that\\'d\": \"that would / that had\",\\r\\n\"that\\'d\\'ve\": \"that would have\",\\r\\n\"that\\'s\": \"that has / that is\",\\r\\n\"there\\'d\": \"there had / there would\",\\r\\n\"there\\'d\\'ve\": \"there would have\",\\r\\n\"there\\'s\": \"there has / there is\",\\r\\n\"they\\'d\": \"they had / they would\",\\r\\n\"they\\'d\\'ve\": \"they would have\",\\r\\n\"they\\'ll\": \"they shall / they will\",\\r\\n\"they\\'ll\\'ve\": \"they shall have / they will have\",\\r\\n\"they\\'re\": \"they are\",\\r\\n\"they\\'ve\": \"they have\",\\r\\n\"to\\'ve\": \"to have\",\\r\\n\"wasn\\'t\": \"was not\",\\r\\n\"we\\'d\": \"we had / we would\",\\r\\n\"we\\'d\\'ve\": \"we would have\",\\r\\n\"we\\'ll\": \"we will\",\\r\\n\"we\\'ll\\'ve\": \"we will have\",\\r\\n\"we\\'re\": \"we are\",\\r\\n\"we\\'ve\": \"we have\",\\r\\n\"weren\\'t\": \"were not\",\\r\\n\"what\\'ll\": \"what shall / what will\",\\r\\n\"what\\'ll\\'ve\": \"what shall have / what will have\",\\r\\n\"what\\'re\": \"what are\",\\r\\n\"what\\'s\": \"what has / what is\",\\r\\n\"what\\'ve\": \"what have\",\\r\\n\"when\\'s\": \"when has / when is\",\\r\\n\"when\\'ve\": \"when have\",\\r\\n\"where\\'d\": \"where did\",\\r\\n\"where\\'s\": \"where has / where is\",\\r\\n\"where\\'ve\": \"where have\",\\r\\n\"who\\'ll\": \"who shall / who will\",\\r\\n\"who\\'ll\\'ve\": \"who shall have / who will have\",\\r\\n\"who\\'s\": \"who has / who is\",\\r\\n\"who\\'ve\": \"who have\",\\r\\n\"why\\'s\": \"why has / why is\",\\r\\n\"why\\'ve\": \"why have\",\\r\\n\"will\\'ve\": \"will have\",\\r\\n\"won\\'t\": \"will not\",\\r\\n\"won\\'t\\'ve\": \"will not have\",\\r\\n\"would\\'ve\": \"would have\",\\r\\n\"wouldn\\'t\": \"would not\",\\r\\n\"wouldn\\'t\\'ve\": \"would not have\",\\r\\n\"y\\'all\": \"you all\",\\r\\n\"y\\'all\\'d\": \"you all would\",\\r\\n\"y\\'all\\'d\\'ve\": \"you all would have\",\\r\\n\"y\\'all\\'re\": \"you all are\",\\r\\n\"y\\'all\\'ve\": \"you all have\",\\r\\n\"you\\'d\": \"you had / you would\",\\r\\n\"you\\'d\\'ve\": \"you would have\",\\r\\n\"you\\'ll\": \"you shall / you will\",\\r\\n\"you\\'ll\\'ve\": \"you shall have / you will have\",\\r\\n\"you\\'re\": \"you are\",\\r\\n\"you\\'ve\": \"you have\"\\r\\n}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8escefS_AZq",
        "colab_type": "code",
        "outputId": "f9bac131-117f-4177-8c1e-d8c9f50da5d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0E6YjG2-uJ8",
        "colab_type": "code",
        "outputId": "c9b1166c-b080-417e-9111-9c5e79b1055b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "#importing AttetionLayer from the uploaded attention.py\n",
        "from attention import AttentionLayer\n",
        "\n",
        "#importing contraction_mapping from contractions\n",
        "from contractions import contraction_mapping"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKh78c4fCbrg",
        "colab_type": "text"
      },
      "source": [
        "# Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-_Qu8rw_OLl",
        "colab_type": "code",
        "outputId": "259157f9-9b59-44a2-ea99-10482d9bdd00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re \n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from tensorflow.keras.models import Model \n",
        "from tensorflow.keras.callbacks import EarlyStopping \n",
        "\n",
        "import warnings  \n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azG19vPMCjo8",
        "colab_type": "text"
      },
      "source": [
        "# Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOFNVFEWAz3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Data/Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auLmAJ1-fVNC",
        "colab_type": "code",
        "outputId": "f78c1c1d-23f9-45a6-8b32-358493a22492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWiQdnS9evRh",
        "colab_type": "text"
      },
      "source": [
        "Drop duplicates and NA values\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEXnrfXSeuWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dropping duplicates\n",
        "data.drop_duplicates(subset=['Text'], inplace=True)\n",
        "\n",
        "#dropping na values\n",
        "data.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WBKqjXAs0t0",
        "colab_type": "text"
      },
      "source": [
        "# Text cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5wyLmiGszxS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "9e8ed893-7622-47e2-ec06-f4b06bb1c292"
      },
      "source": [
        "#Looking at the text\n",
        "data['Text'][:10]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    I have bought several of the Vitality canned d...\n",
              "1    Product arrived labeled as Jumbo Salted Peanut...\n",
              "2    This is a confection that has been around a fe...\n",
              "3    If you are looking for the secret ingredient i...\n",
              "4    Great taffy at a great price.  There was a wid...\n",
              "5    I got a wild hair for taffy and ordered this f...\n",
              "6    This saltwater taffy had great flavors and was...\n",
              "7    This taffy is so good.  It is very soft and ch...\n",
              "8    Right now I'm mostly just sprouting this so my...\n",
              "9    This is a very healthy dog food. Good for thei...\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VizZIhr7gM-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b20a4b8b-cbb8-4170-bb44-0e87cb588775"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words= set(stopwords.words('english'))\n",
        "\n",
        "def text_cleaner(text):\n",
        "    #Converting everything to lowerr case\n",
        "    newString = text.lower()\n",
        "\n",
        "    #Remove HTML tags\n",
        "    newString = BeautifulSoup(newString, \"lxml\").text\n",
        "\n",
        "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
        "    newString = re.sub('\"', '', newString)\n",
        "\n",
        "    #Contraction mapping\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])\n",
        "\n",
        "    #Removing 's \n",
        "    newString = re.sub(r\"'s\\b\", \"\", newString)\n",
        "\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    tokens = [w for w in newString.split() if w not in stop_words]\n",
        "\n",
        "    long_words = []\n",
        "    for i in tokens:\n",
        "        if len(i) > 3:\n",
        "            long_words.append(i)\n",
        "    \n",
        "    return (\" \".join(long_words).strip())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjEYKJnXw3AQ",
        "colab_type": "text"
      },
      "source": [
        "# Summary cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUeuafjNweoD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0940b24d-d847-47dc-dcee-eadfe21a1ca3"
      },
      "source": [
        "#Looking at the summaries\n",
        "data['Summary'][:10]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0                            Good Quality Dog Food\n",
              "1                                Not as Advertised\n",
              "2                            \"Delight\" says it all\n",
              "3                                   Cough Medicine\n",
              "4                                      Great taffy\n",
              "5                                       Nice Taffy\n",
              "6    Great!  Just as good as the expensive brands!\n",
              "7                           Wonderful, tasty taffy\n",
              "8                                       Yay Barley\n",
              "9                                 Healthy Dog Food\n",
              "Name: Summary, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGmiHIMOxUeK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summary_cleaner(text):\n",
        "    newString = re.sub('\"', '', text)\n",
        "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])\n",
        "    newString = re.sub(r\"'s\\b\", \"\", newString)\n",
        "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString)\n",
        "    newStrig = newString.lower()\n",
        "\n",
        "    tokens = newString.split()\n",
        "    newString = ''\n",
        "    for token in tokens:\n",
        "        if len(token) > 3:\n",
        "            newString = newString + token + ' '\n",
        "    \n",
        "    return newString"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR4ujb3TydPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(text_cleaner(t))\n",
        "\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(summary_cleaner(t))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gNo9UsZzIKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_text'] = cleaned_text\n",
        "data['cleaned_summary'] = cleaned_summary\n",
        "\n",
        "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4VqpiW00kvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "34c28ce9-61e7-47ea-92cf-672f0984370f"
      },
      "source": [
        "cleaned_data = data[['cleaned_text', 'cleaned_summary']]\n",
        "cleaned_data.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cleaned_text</th>\n",
              "      <th>cleaned_summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bought several vitality canned food products f...</td>\n",
              "      <td>Good Quality Food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>product arrived labeled jumbo salted peanuts p...</td>\n",
              "      <td>Advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>confection around centuries light pillowy citr...</td>\n",
              "      <td>Delight says</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>looking secret ingredient robitussin believe f...</td>\n",
              "      <td>Cough Medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great taffy great price wide assortment yummy ...</td>\n",
              "      <td>Great taffy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        cleaned_text     cleaned_summary\n",
              "0  bought several vitality canned food products f...  Good Quality Food \n",
              "1  product arrived labeled jumbo salted peanuts p...         Advertised \n",
              "2  confection around centuries light pillowy citr...       Delight says \n",
              "3  looking secret ingredient robitussin believe f...     Cough Medicine \n",
              "4  great taffy great price wide assortment yummy ...        Great taffy "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InmDeAQg1CNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting cleaned_data dataFrame into a csv file\n",
        "cleaned_data.to_csv('cleanedData.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubqOMJGp13ob",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copying the csv file to google drive\n",
        "!cp /content/cleanedData.csv /content/drive/My\\ Drive/Data"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}